{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwords(doc):\n",
    "    splitter = re.compile('\\\\W+')\n",
    "    words = [s.lower() for s in re.split(splitter,doc) if len(s) > 2 and len(s) < 30]\n",
    "    return dict([(word,1) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'like': 1, 'programming': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getwords('I like programming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier:\n",
    "    def __init__(self, getfeatures,filename=None):\n",
    "#         classifier.__init__ = (self,getfeatures)\n",
    "        self.fc = {} # 统计特征/分类组合的数量 e.g {'python': {'bad':0,'good':6},'the':{'bay':3,'good':3}}\n",
    "        self.cc = {} # 统计每个分类的文档数量\n",
    "        self.getfeatures = getfeatures\n",
    "        self.thresholds = {}\n",
    "        \n",
    "        \n",
    "    def incf(self, feature, category):\n",
    "        self.fc.setdefault(feature,{})\n",
    "        self.fc[feature].setdefault(category,0)\n",
    "        self.fc[feature][category] += 1\n",
    "\n",
    "    def incc(self, category):\n",
    "        self.cc.setdefault(category,0)\n",
    "        self.cc[category] += 1\n",
    "\n",
    "    def fcount(self,feature, category):\n",
    "        if feature in self.fc and category in self.fc[feature]:\n",
    "            return float(self.fc[feature][category])\n",
    "        return 0.0\n",
    "\n",
    "    def catcount(self, category):\n",
    "        if category in self.cc:\n",
    "            return float(self.cc[category])\n",
    "        return 0.0\n",
    "    def totalcount(self):\n",
    "        return sum(self.cc.values())\n",
    "\n",
    "    def categories(self):\n",
    "        return self.cc.keys()\n",
    "\n",
    "    def train(self, doc, category):\n",
    "        word_count = self.getfeatures(doc)\n",
    "        for feature in word_count:\n",
    "            self.incf(feature,category)\n",
    "        self.incc(category)\n",
    "        \n",
    "    def fprob(self, feature, category):\n",
    "        if self.catcount(category) == 0.0 or category not in self.fc[feature]: return 0\n",
    "        return float(self.fc[feature][category]) / float(self.catcount(category))\n",
    "    \n",
    "    def weightprob(self, feature, cat, prf, weight = 1.0, ap=0.5):\n",
    "        basicprob = prf(feature, cat)\n",
    "        totals = sum([self.fcount(feature,c) for c in self.categories()])\n",
    "        bp = ((weight * ap) + (totals*basicprob)) / (weight + totals)\n",
    "        return bp\n",
    "    \n",
    "    def setthreshold(self, category, val):\n",
    "        self.thresholds[category] = val\n",
    "        \n",
    "    def getthreshold(self, category):\n",
    "        if category not in self.thresholds:\n",
    "            return 1.0\n",
    "        return self.thresholds[category]\n",
    "    \n",
    "    def classify(self, doc, default=None):\n",
    "        probs = {}\n",
    "        categories = self.categories()\n",
    "        for cat in categories:\n",
    "            probs[cat] = self.prob(doc,cat)\n",
    "        # print(probs) \n",
    "        # best_category = max(zip(probs.keys(),probs.values()))\n",
    "        \n",
    "        best_two = heapq.nlargest(2,probs.items(),key=lambda x:x[1])\n",
    "        print(best_two)\n",
    "        if self.getthreshold(best_two[1][0]) * best_two[1][1] < best_two[0][1]:\n",
    "            return best_two[0][0]\n",
    "        else:\n",
    "            return default\n",
    "        \n",
    "        \n",
    "cl = classifier(getwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampletrain(cl):\n",
    "    cl.train('Nobody owns the water.','good')\n",
    "    cl.train('the quick rabbit jumps fences', 'good')\n",
    "    cl.train('buy pharmaceuticals now', 'bad')\n",
    "    cl.train('make quick money at the online casino','bad')\n",
    "    cl.train('the quick brown fox jumps', 'good')\n",
    "    \n",
    "sampletrain(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "money在bad分类中\n",
      "0.5\n",
      "money在good分类中\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "# 多次执行看数值的变化\n",
    "print('money在bad分类中')\n",
    "print(cl.weightprob('money','bad',cl.fprob))\n",
    "print('money在good分类中')\n",
    "print(cl.weightprob('money','good',cl.fprob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 看重点\n",
    "\n",
    "这里引入weightprob是用来判断一个特征词对于某个分类的贡献是否可信。从上面的语料库中看出，money只在bad分类中出现，而在good分类中一个都没有，这样对于新的测试集中的文本而言，带有money的文本将会全部判为bad分类，显然这是不正确的。除了扩大语料集外，我们还应该对某个词对某个分类的可信度进行测量，这就是weightprob函数的作用！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class naivebayes(classifier):\n",
    "    def docprob(self,doc,category):\n",
    "        features = self.getfeatures(doc)\n",
    "        \n",
    "        multi = 1\n",
    "        for f in features:\n",
    "            multi *= self.weightprob(f,category,self.fprob)\n",
    "        return multi\n",
    "    \n",
    "    def prob(self, doc, category):\n",
    "        category_prob = self.catcount(category) / self.totalcount()\n",
    "        doc_prob = self.docprob(doc, category)\n",
    "        return category_prob * doc_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03580729166666666\n",
      "0.0010416666666666667\n"
     ]
    }
   ],
   "source": [
    "n = naivebayes(getwords)\n",
    "sampletrain(n)\n",
    "print(n.prob('the quick rabbit jumps fences','good'))\n",
    "print(n.prob('the quick rabbit jumps fences','bad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good', 0.15624999999999997), ('bad', 0.05)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.classify('quick rabbit',default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bad', 0.1), ('good', 0.09375)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bad'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.classify('quick money',default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bad', 0.1), ('good', 0.09375)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bad'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.setthreshold('bad',3)\n",
    "n.classify('quick money',default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fisherclassifier(classifier):\n",
    "    def __init__(self, getfeatures,filename=None):\n",
    "        classifier.__init__(self,getfeatures)\n",
    "        self.thresholds = {}\n",
    "        \n",
    "    def cprob(self, feature, category):\n",
    "        clf = self.fprob(feature, category)\n",
    "        if clf == 0:\n",
    "            return 0\n",
    "        freqsum = sum([self.fprob(feature, cat) for cat in self.categories()])\n",
    "        p = clf / freqsum\n",
    "        return p\n",
    "    \n",
    "    def fisherprob(self, doc, category):\n",
    "        p = 1\n",
    "        features = self.getfeatures(doc)\n",
    "        for feature in features:\n",
    "            f_c = self.cprob(feature,category)\n",
    "            if f_c:\n",
    "                p *= self.cprob(feature,category)\n",
    "        res = math.log(p) * (-2)\n",
    "        return self.invchi2(res,len(features)*2)\n",
    "    \n",
    "    # 结果归一化函数\n",
    "    def invchi2(self,chi,df):\n",
    "        m = chi / 2.0\n",
    "        sum = term = math.exp(-m)\n",
    "        for i in range(1, df//2):\n",
    "            term *= m/i\n",
    "            sum += term\n",
    "        return min(sum,1)\n",
    "    \n",
    "    def setthresholds(self,category,val):\n",
    "        self.thresholds[category] = val\n",
    "        \n",
    "    def getthresholds(self,category):\n",
    "        if category in self.thresholds:\n",
    "            return self.thresholds[category]\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def classify(self,doc,default=None):\n",
    "        categories = self.categories()\n",
    "        res = {}\n",
    "        best = default\n",
    "        max_val = 0.0\n",
    "        for cat in categories:\n",
    "            p = self.fisherprob(doc, cat)\n",
    "            if p > self.getthresholds(cat) and p > max_val:\n",
    "                best = cat\n",
    "                max_val = p\n",
    "        return best\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285715\n",
      "1.0\n",
      "1.0\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "f = fisherclassifier(getwords)\n",
    "sampletrain(f)\n",
    "print(f.cprob('quick','good'))\n",
    "print(f.cprob('money','bad'))\n",
    "print(f.cprob('casino','bad'))\n",
    "print(f.weightprob('money','bad',f.cprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285715"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.fisherprob('quick','good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.classify('the quick rabbit jumps fences')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
